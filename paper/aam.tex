Abstracting abstract machines is founded on three ideas:
\begin{enumerate}
\item{recursive data structures are easily representable via indirection through a map at recursive points. For example, the tail of a list goes from being a list to an address of a list in a heap;}
\item{a finite pool of addresses then means a finite state space;}
\item{reused addresses mean the heap must use weak updates: $[a \mapsto v]\sqcup[a \mapsto v'] = [a \mapsto \set{v,v'}]$ and lookups make non-deterministic choices.}
\end{enumerate}

\subsection{Notations and conventions}
\begin{itemize}
\item{$D \finto R$ \textbf{:} a finite function from domain $D$ to codomain $R$.}
\item{$\setbuild{\mathit{term}}{\mathit{formula}}$ \textbf{:} a set comprehension where the free variables are implicitly existentially bound. Consider it a set denotation of a $\Sigma$ type.}
\item{We use $\widehat{\mathit{space}}$ to say a space is an abstracted form of the concrete semantics' analogous $\mathit{space}$. We will not add hats to spaces that are added to the abstraction.}
\item{Similarly, elements of abstract spaces have hats: \eg{} $\makont \in \sa{Kont}$.}
\item{We will write $n$-tuples as $\tpl{t_1,\ldots,t_n}$, $(t_1,\ldots,t_n)$ or just $t_1,\ldots,t_n$, and their $i^\text{th}$ projections as $\pi_i$.}
\item{$\sqcup$ \textbf{:} a join operator that lifts pointwise over tuples and functions. Sets are unioned. Ground terms are implicitly lifted to singleton sets.}
\item{$S^*$ \textbf{:} the space of lists of elements of $S$.}
\item{$\epsilon$ \textbf{:} the empty list.}
\item{$\kcons{a}{l}$ \textbf{:} a list $l$ with $a$ added to the front.}
\item{$\append{l}{l'}$ \textbf{:} list $l'$ appended to list $l$.}
\item{$g \to t, e$ \textbf{:} Dijkstra notation for ``if $g$ then $t$ else $e$''}
\item{$t \deceq t'$ \textbf{:} a Boolean decision for equality of terms $t$ and $t'$.}
\item{$\extm{\menv}{\mvar}{\maddr}$ \textbf{:} $\lambda \mvaralt. \mvar \deceq \mvaralt \to \maddr, \menv(\mvaralt)$.}
\item{$\mathit{elem} \in \mathit{Space} ::= \mathit{term} \alt \ldots$ \textbf{:} a set of Backus-Nauer-form alternates that inductively define a space $\mathit{Space}$. The $\mathit{term}$s in each alternate are constructors where element variables like $\mathit{elem}$ denote their containing space. Unwrapped elements of other spaces are implicitly injected. Refined constructors of other spaces are overloaded for the refining space.

For example:
\begin{align*}
  \mvar \in \mathit{Variable} &\text{ a set} \\
  \mexpr \in \Expr &::= \svar{\mvar} \alt \sapp{\mexpr}{\mexpr} \alt \slam{\mvar}{\mexpr} \\
  \mval \in \Value &::= \slam{\mvar}{\mexpr}
\end{align*}
can be written as inductive datatypes with no overloading
\begin{verbatim}
Parameter Variable : Set.
Inductive Expr : Set :=
| var : Variable -> Expr
| app : Expr -> Expr -> Expr
| lam : Variable -> Expr -> Expr.
Inductive Value : Set :=
| vlam : Variable -> Expr -> Value.
\end{verbatim}}
\item{We use element variables to treat tuples with record syntax. For example, For a space defined like $\mstate \in \State ::= \tpl{\mexpr,\menv,\mkont}$, we may write $\mstate.\mkont$ to mean that there exists some $\mexpr',\menv',\mkont'$ such that $\mstate = \tpl{\mexpr',\menv',\mkont'}$ and $\mstate.\mkont = \mkont'$. We may also write $\mstate\{\menv := \bot\}$ to mean $\tpl{\mexpr',\bot,\mkont'}$.}
\item{$s \stepto s'$ \textbf{:} a state $s$ steps to another state $s'$ via a reduction relation $\stepto \subseteq \State \times \State$. The relation should be clear from the context and the space of $s, s'$.}
\item{$\mtrace$ \textbf{:} a trace with respect to some reduction relation $\stepto$, \ie{}, a sequence of states $\set{s_i}_{i=0}^n$ such that this proposition holds $\IsTrace(\mtrace) = \forall i \in [0..n-1). s_i \stepto s_{i+1}$}
\item{We implicitly reassociate tuples or splice them into a larger context to have a cleaner presentation.
For example, we may write $\tpl{\menv(\mexpr), \mkont}$ for an element of $\Expr \times \Env \times \Kont$ instead of ``$\tpl{\mval,\menv',\mkont}$ where $(\mval,\menv') = \menv(\mvar)$.''}
\end{itemize}

\subsection{The $\CESKstart$ machine}

Concretely, let us consider an abstract machine for the call-by-value untyped lambda calculus: the CEK machine.
%
The semantic spaces in \autoref{fig:cek-spaces} have three points of recursion: subexpressions, closures and pushed continuation frames.
%
The semantics for the CEK machine in \autoref{fig:cek-semantics} shows the delayed substitution semantics that environments enable.
%
Function application delays the substitution of an argument by extending the enviroment.
%
Variables dereference the environment to fulfill the delayed substitution semantics that the CEK machine implements.
%
Function application performs an administrative step to search for the next redex.
\begin{figure}\centering  
  \begin{align*}
    \mstate \in \CEK &::= \tpl{\mexpr, \menv, \mkont} \\
    \mexpr \in \Expr &::= \svar{\mvar} \alt \sapp{\mexpr}{\mexpr} \alt \mval \\
    \mval \in \Value &::= \slam{\mvar}{\mexpr} \\
    \menv \in \Env &= \Var \finto \Value \times \Env \\
    \mkframe \in \Frame &::= \appl{\mexpr,\menv} \alt \appr{\mval,\menv} \\
    \mkont \in \Kont &= \Frame^* \\
    \mvar \in \Var & \text{ a set}
  \end{align*}
  \caption{CEK semantic spaces}
\label{fig:cek-spaces}
\end{figure}

\begin{figure}
  \centering
  $\mstate \stepto \mstate'$ \\
  \begin{tabular}{r|l}
    \hline\vspace{-3mm}\\
    $\tpl{\svar\mvar, \menv, \mkont}$
    &
    $\tpl{\mval, \menv', \mkont}$ if $(\mval,\menv') = \menv(\mvar)$
    \\
% Application
    $\tpl{\sapp{\mexpri0}{\mexpri1},\menv,\mkont}$
    &
    $\tpl{\mexpri0,\menv,\kcons{\appl{\mexpri1,\menv}}{\mkont}}$
    \\
% Arg eval
    $\tpl{\mval,\menv, \kcons{\appl{\mexpr,\menv'}}{\mkont}}$
    &
    $\tpl{\mexpr,\menv',\kcons{\appr{\mval,\menv}}{\mkont}}$
    \\
% Function call
    $\tpl{\mval,\menv,\kcons{\appr{\slam{\mvar}{\mexpr},\menv'}}{\mkont}}$
    &
    $\tpl{\mexpr,\menv'[\mvar\mapsto(\mval,\menv)],\mkont}$
  \end{tabular}
  \caption{CEK machine}
  \label{fig:cek-semantics}
\end{figure}

The recursion in expressions is beneign because they are only destructed. The $\Expr$ space is finite for each program, the size of which is the number of subexpressions.
%
The run-away recursion is in $\Env$ and $\Kont$.
%
AAM suggests that the codomain of $\Env$ and the tail of the $\Frame$ list in $\Kont$ should instead be some $\Addr$ space.\footnote{The strict criteria suggests $\Env : \Var \finto \Value \times \Addr$, but $\Var \finto \Addr$ is a sound approximation and has a similar shape to other analyses' approximations.}
%
Extensions to maps in $\Env$, and conses of frames in $\Kont$ then instead allocate an address, update the heap with the recursive value, and use the address in place of the recursive value.
%
To help an $\alloc : \State \to \Addr$ function choose its addresses, the state space can be extended with an arbitrary pointed space that can be updated each step.
%
The original AAM paper calls this pointed space and update function $(\Time,\mtime_0)$ and $\tick$ respectively.
%
Later work on widening~\citep{ianjohnson:DBLP:conf/vmcai/HardekopfWCK14} suggests less arbitrary constructions, and to think of $\Time$ as a space of abstract traces, though the ``abstraction'' need not be sound~\citep{dvanhorn:Might2009Posteriori}.

The new semantic spaces in \autoref{fig:ceskstart-spaces} form the $\CESKstart$ machine.
%
We represent the machine differently than the original AAM paper to separate induced components (\eg{} the store and $\Time$) from transformed components (\eg{} the environment) for a uniform presentation.
%
The semantics of this machine follow the weak update and non-deterministic lookup principles of AAM in \autoref{fig:ceskstart-semantics}.

\begin{figure}
  \centering
  \begin{align*}
    \mastate \in \sa{CEK} &::= \tpl{\mexpr, \maenv, \makont} \\
    \sa{State} &= \sa{CEK} \times \Store \times \Time \\
    \mstore \in \Store &= \Addr \to \Storeable \\
    \maenv \in \sa{Env} &= \Var \finto \Addr \\
    \makont \in \sa{Kont} &::= \epsilon \alt \kcons{\mkframe}{\maddr} \\
    \Storeable &= \wp(\sa{Kont} + (\Value \times \sa{Env})) \\
    \maddr,\maddralt \in \Addr & \quad \mtime,\mtimealt \in \Time
  \end{align*}
  \caption{$\CESKstart$ semantic spaces}
  \label{fig:ceskstart-spaces}
\end{figure}

\begin{figure}
  \centering
  $\mastate,\mstore,\mtime \stepto \mastate',\mstore',\tick(\mastate,\mstore,\mtime)$ \quad $\maddr = \alloc(\mastate,\mstore,\mtime)$ \\
  \begin{tabular}{r|l}
    \hline\vspace{-3mm}\\
    $\tpl{\svar\mvar, \maenv, \makont}$
    &
    $\tpl{\mval, \maenv',\makont}$ if $(\mval,\menv') \in \mstore(\maenv(\mvar))$
    \\
% Application
    $\tpl{\sapp{\mexpri0}{\mexpri1},\maenv,\makont}$
    &
    $\tpl{\mexpri0,\maenv,\kcons{\appl{\mexpri1,\maenv}}{\maddr}}$ \\
    where & $\mstore' = \joinm{\mstore}{\maddr}{\makont}$
    \\
% Arg eval
    $\tpl{\mval,\maenv, \kcons{\appl{\mexpr,\maenv'}}{\maddralt}}$
    &
    $\tpl{\mexpr,\maenv',\kcons{\appr{\mval,\maenv}}{\maddralt}}$
    \\
% Function call
    $\tpl{\mval,\maenv,\kcons{\appr{\slam{\mvar}{\mexpr},\maenv'}}{\maddralt}}$
    &
    $\tpl{\mexpr,\maenv'',\makont}$ if $\makont \in \mstore(\maddralt)$ \\
    where & $\maenv'' = \maenv'[\mvar\mapsto\maddr]$ \\
          & $\mstore' = \joinm{\mstore}{\maddr}{(\mval,\maenv)}$
  \end{tabular} \\
  Where $\mstore' = \mstore$ unless otherwise stated.
  \caption{$\CESKstart$ semantics}
  \label{fig:ceskstart-semantics}
\end{figure}

If we run the $\CESKstart$ semantics to explore all possible states, we get a sound approximation of all paths that the $\CEK$ machine will explore.
%
The paper will give a more focused view of the $\Kont$ component.
%
Suppose a semantics that interacts with $\Kont$ via a stack discipline (only push and pop single frames at a time, \eg{} the above machine).
%
If we were not to heap-allocate the tail of a continuation, the resulting machine has all finite components except an unbounded stack of finitely many stack frames.
%
This is exactly a pushdown system.
%
We can exactly represent the stack and still have a sound and terminating analysis.